---
layout: default
title: Reading 5
has_children: false
parent: ðŸ“š Readings
nav_order: 5
permalink: /readings/reading-5
---

# Reading 5

- Nicholas Diakopoulos, 2016, Accountability in Algorithmic Decision Making <a href="https://s3.us-west-2.amazonaws.com/ucsd.cogs9/readings/r5a-algorithmic-decision-making.pdf" target="_blank" rel="noopener">download &#x2197;</a>
- Julia Angwin, et al., 2016, Machine Bias <a href="https://s3.us-west-2.amazonaws.com/ucsd.cogs9/readings/r5b_machine_bias.pdf" target="_blank" rel="noopener">download &#x2197;</a>

These readings are more about the issues with machine learning, rather than how to go about building cool models. In class we cover some of the awesome stuff you can accomplish with data and algorithms. But these readings are here to allow you to better see some of the inherent flaws, and data generating issues that these models learn from. These flaws are not just academic, but they really do exist in currently used machine learning systems. If we want to build technology to serve people, and improve society, we must really learn to understand and identify areas where machine learning is not working well, or being misapplied. 

## Additional Resources

Here is an interesting game you can <a href="https://www.survivalofthebestfit.com/" target="_blank" rel="noopener">play &#x2197;</a> that teaches you how algorithms learn to fit a bias from the data generating process, as well as, the decisions that people make using the system. Feedback loops can be very dangerous to a system, and with machine learning it can reinforce, at first, benign issues with data or decisions.

